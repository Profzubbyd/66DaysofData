My 66 Days Journey Into The World Of Data Science

## Books
|   |                                          |
|---|------------------------------------------|
| 1 | [An Introduction to Statistical Learning](http://amzn.to/2naqf6h) |
| 2 | [Hands-On Machine Learning with Scikit-Learn and TensorFlow](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291) |

## Podcasts
|   |                                          | 
|---|------------------------------------------|
| 1 | [Linear Digressions](http://lineardigressions.com/) |
| 2 | [Not So Standard Deviations](https://soundcloud.com/nssd-podcast) |
| 3 | [Data Skeptic](https://dataskeptic.com/) |
| 4 | [Data Science at Home Podcast](http://worldofpiggy.com/podcast/) |
| 5 | [O'Reilly Data Show Podcast ideas and resources](https://www.oreilly.com/topics/oreilly-data-show-podcast) |
| 6 | [Data Stories](http://datastori.es/) |
| 7 | [Talking Machines](http://www.thetalkingmachines.com/) |

## Courses
|   |                                          | 
|---|------------------------------------------|
| 1 | [Python](https://www.kaggle.com/learn/python) |
| 2 | [Pandas](https://www.kaggle.com/learn/pandas) |
| 3 | [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) |
| 4 | [Data Visualization](https://www.kaggle.com/learn/data-visualization) |


### Day 1
I'm very excited to be a part of this challenge.
- Today I learnt more about Github through a freeCodeCamp video: https://youtu.be/RGOj5yH7evk
- I created a repository for this challenge to have a detailed record of my progress.
- I learnt about External dictionaries in Python. How to work with them and get more details about them. I learnt this through the Kaggle course: https://www.kaggle.com/colinmorris/working-with-external-libraries

### Day 2
- Today I finished the Kaggle Python course: https://www.kaggle.com/learn/python
- It covered functions, loops, booleans, lists, strings and libraries. It was a really practical course.
<img src="https://user-images.githubusercontent.com/46527701/103698248-5dfb2080-4fa1-11eb-9a88-9bbb48265906.png" width="700" height="450">

### Day 3
- Learnt about Data Ethics and Scaling Machine Learning today from the Data Science from Home Podcast. Good episodes
- Data Ethics are principles that guide people to do good while using data to build anything

#### 5 Principles guiding Data Ethics
1. Human centric: Interest of human before commercial gain.
2. Equality: Should show reality of how diverse we are adn the impact to other different communities
3. Control: Full control to individuals you want to help
4. Transparency: Say what you do and do what you say. People should understand clearly what they are buying into.
5. Accountable: Be accountable through out the whole process from data collection to decision making.

- I also learnt about scaling and handling big data. GPUs do a good job here because they are faster than CPUs but a lot less RAM.
- Tools for scaling include Hadoop, Spark, RAPIDS, Dask.
- I've always been seeing RAPIDS around but today I learnt what it means. Excited about the days ahead.

### Day 4
- Today I started the Kaggle course Intro to SQL and completed 3 modules with practice exercises. I learnt the full meaning of SQL. Didn't know this before. Also how to access and examine BigQuery Datasets. Learnt about clients, projects, tables, etc. Learnt how to write SQL queries with SELECT, FROM, WHERE, GROUP BY, HAVING and COUNT. Learnt that there are datasets as large as 3TB. Wow!!! This is why you need to set a limit on queries you fetch. I saw that it is really with SQL we can really analyse and ask interesting questions about data.

- Also listened to "Becoming a machine learning practitioner" on O'Reilly Data Show Podcast. Was a great episode. A good was to learn ML is through building a project then learning the data science process behind it. The host uses AWS and codes as an Amazon ML developer. I learnt the value of attending lots of technical conferences. I also learnt that ML practitioners also have a reponsibility of educating their managers on ML use-cases since they are at the decison making layer.

### Day 5
- Today I completed the Kaggle course: Intro to SQL. Learnt about ORDER BY, AS WITH, CTEs and JOINING tables. I just found myself loving SQL. I realized you can ask so many interesting questions and also make analysis from several datasets (and tables in them). I highly recommend the course.
- I also listened to "One Hot 2020" on Not So Standard Deviations Podcast. I learnt a lot of use-cases of AI(Artificial Intelligence) and ML(Machine Learning). The hosts Roger Peng and Hilary Parker analysed the differences between AI and ML. To mention one, AI systems come to you as a person and there's always real-time interaction eg self driving cars while ML just uses data from your past activities like recommender systems, Google Autofill, etc. It was a fun episode.
<img src="https://user-images.githubusercontent.com/46527701/104059810-32bd3f00-51f6-11eb-8941-ce1d8ecd79f5.png" width="700" height="450">

### Day 6
- Today I continued my "Big Data Analytics with Python - Day 5" course being offered by Utiva which I take every weekend. They have a great instructor. I learnt about Pandas today.
- Specifically, I learnt that pandas is very fundamental for any Data Scientist. 
- Also learnt about Pandas Series, Dataframes and several things that can be done with them. A lot of work went into building pandas. There are so many things that can be done with it. It just makes data manipulation easier.

### Day 7
- Today I continued my "Big Data Analytics with Python - Day 6" course being offered by Utiva which I take every weekend. We finished up Pandas today. 
- We explored the Groupby function, it's very similar to that of SQL. We also looked at merging, joining and concatenation.
- I learnt about visualization. A light intro to the blend of Pandas and matplotlib. Histogram, Bar chart, Scatter, Box & Line plot amongst others.
- Visualization is a tool every Data Scientist must learn. That's how we tell the data story.

### Day 8
- Today, I started Kaggle course: Pandas. It gave me hands-on learning of the concepts I got exposed to over the weekend.
- I learnt about indexing, selecting and assigning in Pandas. I also learnt about Summary functions and mapping in Pandas. 
Having a Maths background helped me to understand the mapping process better.
- Something interesting about today's learning experience was the difference between iloc and loc indexing scheme. The fact that iloc uses Python stdlib indexing scheme while loc doesn't.

### Day 9
- Today, I finished the Kaggle course: Pandas. It was a highly practical course.
- I learnt about Groupby, Multi-indexing, Sorting, Checking and Changing Datatypes, Handling missing values, Renaming and Combining with concat, join and merge.
I love playing with pandas. The things you can do with it are really a lot.
- There isn't much to say today as I really got my hands dirty with code.
<img src="https://user-images.githubusercontent.com/46527701/104376854-e2135200-5525-11eb-9687-ed91f5e42d57.png" width="700" height="450">

### Day 10
- Today, I started the Kaggle course: Data Visualization. This was where Kaggle really broke python down. A lot of basic things.
- I learnt about Seaborn specifically; lineplots, bar charts and heatmaps.
- There is a whole lot that visualization can reveal. Looking at tables you may just see numbers but with visualization you can do analysis and make decisions.
Heatmaps especially can give an eagle-eye view over everything. It's really beautiful.

### Day 11
- Today, I completed the Kaggle course: Data Visualization. Learnt about Scatter plots, Histogram, Density plots and changing sea born styles.
- I learnt how to extract and analyse datasets. Specifically, I analysed the [Housing in London dataset](https://www.kaggle.com/justinas/housing-in-london). I found some interesting things from the visualization:
1. Monthly crime rate is positively correlated with the number of houses sold. This is intuitive actually since people won't want to get a house in neighbourhoods with high crime rate.
2. The number of jobs per year is positively correlated with the population size of the city. So bigger cities have more jobs in United kingdom? Was shocked to see that.
Excited about the days ahead.
<img src="https://user-images.githubusercontent.com/46527701/104647844-ba9dc000-56b2-11eb-8b53-aaf23dfbc1ee.png" width="700" height="450">

Houses Sold vs. Crime Rate             |  Available Jobs vs Population Size
:-------------------------:|:-------------------------:
<img src="https://user-images.githubusercontent.com/46527701/104649423-fcc80100-56b4-11eb-8dd7-828468c89b51.png" width="400" height="400">  |  <img src="https://user-images.githubusercontent.com/46527701/104649429-fdf92e00-56b4-11eb-8bd7-ea524cf6168c.png" width="400" height="400">

### Day 12
- Today, I learnt about time series analysis with R. I figured that it's good to know Python and R so I'm learning and applying both.
- There are a lot of things that can be done with time series. Basically, there are 2 purposes of time series:
1. To model the stochastic (random) mechanism that gives rise to a series of data.
2. To perdict future occurence of the series based on the previous history.

- I also learnt about the Principle of Parsimony: The simpliest model we can make that gives us all the necessary information required in the experiment is sufficient.
This means a lot for me as a data scientist so I don't have to worry about all the data I get.

### Day 13
- Today, I continued my "Big Data Analytics with Python - Day 7" course being offered by Utiva which I take every weekend. We learnt about Matplotlib plots.
- Though I have completed Kaggle's course on Data Visualization during the week, I still learnt a lot from today's class. Learnt about Object oriented plots, during the week I did more of pyplots. 
- This OOPs give you more control of your plots which I see as a very good feature. You can specify axes dimensions, draw a plot within another without doing subplots. Also, learnt about making adjustments to the plots, changing styles, setting limits, etc. Also handled a dataset and did some comparison among variables using plots.

### Day 14
- Today, I continued my "Big Data Analytics with Python - Day 8" course being offered by Utiva which I take every weekend. We learnt about Seaborn plots. The class was really extensive.
- I learnt about Relational plots, Distribution plots, Categorical plots, Regression plots, Matrix plots, and Multi-plot grids (Facet, Pair and Joint grids)
- I really like the class because we learn with the API reference of the documentation. Before now I saw documentation as something far but I've now learn thow to use it through practice.
- I have learnt a lot about Data Visualization (Spending more than 12 hours within 4 days). I'll be switching gears tomorrow.

### Day 15
- Today, I finished the Kaggle course: Intro to Machine Learning. Learnt how to build and validate a model. I also learnt about overfitting and underfitting. You always have to find that sweet spot.
- I learnt 2 models from the scikit-learn library: Decision Trees and Random Forests.
- I also made my first submission in a Kaggle competition today. So happy about this. So much Machine Learning models to build in the future.
<img src="https://user-images.githubusercontent.com/46527701/104965426-fac8af80-59de-11eb-9113-e6168e55f700.png" width="700" height="450">
